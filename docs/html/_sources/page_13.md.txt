---
layout: default
title: "MWlamprop"
---

# **13.-** <span style="color:lightblue">Electrophysiological recordings</span>

![](../../reports/figures/laminae.png){width="900px" align=right}  


![](../../reports/figures/rdm.png){width="900px" align=center}  
![](../../reports/figures/tfr.png){width="900px" align=center}  



**Background.** *Temporal Generalization and Representational Similrity Analysis (TGA and RSA) are multivariate classification methods aimed at assessing the  reinstatement and progression of the distinct neuronal response patterns elicited by stimuli. As such, they have proven effective in probing the visual processing stream at the level of cortical areas.  It remains to be seen, however, if these approaches can reveal meaningful spatiotemporal representational structure during visual processing at the level of cortical laminar circuits.*

**Hypothesis.** *Here we hypotesiyed that, when applied to electrophysiological laminar resposes to naturalistic stimuli, TGA may reflect the unfolding contributions of feedforward, lateral, and feedback to the visual processing stream.*

**Stimuli.** *We presented 36 naturalistic images (18 objects & 18 object + background) to a single Macaque, while recording, using laminar probes, electrophysiological data from the upper bank of one hemisphere's calcarine sulcus. Images were presented in the bottom right quadrant of the visual field at an eccentricity of 3 degrees of visual angle from the fixation point in a random sequence (trial: 1300-1500 ms + 900-1000 ms of gray background). *

**Recording sessions.** *Data from 10 sessions were aligned (at the L4/L5 transition) and  bipolar-LFP was computed and used to derive the spectral power and the goodness of phase relationship (GPR) for theta (3-9 Hz), gamma (35-70 Hz) and high-gamma (100-180 Hz). Multi unit activity (MUA) was also obtained.*


**Response preprocessing.** *Data were grouped into laminar compartments (L2/3, L4,  L5 and L6) and responses classified using linear discriminant analyses (LDA) in and across time steps, as well as across depths, resulting in a collection of  representational dissimilarity matrices (RDM) across time steps. This exploits the cross-generalisability between training and testing sets at different time points. Given a set of trials, a decoder containing information about how the brain responds to the stimulus at the time the decoder is trained is tested on the entire recording time steps. Classification accuracy values were averaged and reported as generalization accuracy (GA). Furthermore, for each depth, classifiers were trained using responses to one condition and generalized, for all other depths, to respones to the other condition. To further scrutinize patterns in the resulting dissimilarity structure, representational similarity analysis (RSA) was computed (using Kendall's Tau correlation between RDMs across depths, both for theta/gamma , as well as within/between conditions). *

**Timeflow of object decoding.** *We find that, for each response, image information could be traced throughout the trial, as well as across distinct depths.*

**Multi-unit activity reflects spiking on input layers.** *For MUA, GA was highest in supra- and sub-granular layers, with increased GA between L2/3 and L5, and widespread but weaker GA across other layers. Interestingly, GAs to L6 tend to generalize to earlier time points  (vertical, upper triangle patterns). *

**Gamma reflects input.** *A similar picture was obtained for theta and gamma, albeit with increased GA from L5 to L2/3 in gamma. Moreover, for gamma, L2/3 did not generalize well to L4.*


**High-gamma show to columnar circuit dynamics.** *Finally, for high-gamma, GA was increased within L2/3 and L5, as well as between L5 and L2/3. Interestingly, vertical and horizontal patterns in GA were observed. Whereas vertical patterns occurred from L2/3 to L4 /L5 and L5 to L4/L6, horizontal patterns unfolded from L4 to L2/3, as well as from L6 to L2/3 & L5.*



**Cross generalization between conditions reveals dynamics of visual processing.** *When applied between conditions, TGA was stronger if classifiers trained with responses to object were generalized  to scenes, rather than the other way around. This is remarkable since GA from objects alone tend to be weaker than that obtained for full scenes.*


**Input layer generalizes to granular and subgranular layers.** *Remarkably, gamma-derived GA from objects to scenes generalized mostly on L2/3 and L5, pointing to feedback modulations related to figure-ground segregation. High-gamma, on the other hand, revealed a timely sharing of information between L5 and L2/3.*



**Clear laminar specificity uncovered with RSA.** *Cross-depth RSA revealed shared stimulus information between theta and gamma in sub-granular supra-granular layers. When applied between conditions, it revealed a different picture than that provided by TGA,  thus highlighting the different scope of these two methods.*

**Discussion.** *Cross-depth TGA and RSA together revealed a characteristic pattern of image-information flow throughout the cortical column, both within and between layers,  reflecting the unfolding contribution of feedforward, lateral and feedback interactions throughout the columnar circuitry during naturalistic image viewing. Can these differences be functionally interpreted?*

**Conclusion.** *Importantly, aggregating features such as spectral power and GPR prior to stimulus-response classification increases the recovery of image information. Our results demonstrate the utility of our combined  spectral-TGA/RSA approach in exploiting spectral measures for capturing layer-specific rhythm interactions across cortical laminae in V1.However, further scrutiny of the assymetric temporal dynamics this study discloses may help clarifying the role that different visual processing regimes play in shaping electrophyiological laminar responses.  This off-diagonalness seemed to reflect the flow of image information throughout the cortical column.  This study relied on data from a single animal. Future studies could include more animals.*
